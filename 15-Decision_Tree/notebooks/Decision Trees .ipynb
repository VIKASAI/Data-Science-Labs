{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1> Decision Trees </h1></center>\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Program so far\n",
    "***\n",
    "- Python Basics and Intermediate\n",
    "- Descreptive and Inferential Statistics\n",
    "- Feature Engineering\n",
    "- Linear Regression\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are we going to learn today ?\n",
    "***\n",
    "- Decision Trees\n",
    "\t- Introduction\n",
    "\t- Representation\n",
    "\t- Intuition\n",
    "\t- Types of Decision Trees based on target variable\n",
    "\t- Terminologies Used\n",
    "\t- Splits in Decision Trees\n",
    "\t- Decision Trees - How does it work ?\n",
    "\t- Gini Index\n",
    "\t- Chi - Square\n",
    "\t- Entropy / Infromation Gain\n",
    "\t- Reduction in Variance\n",
    "- Shortcomings in decsion Trees\n",
    "- Setting Constraints\n",
    "- Advantages of Decision Trees\n",
    "- Drawbacks of Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision Trees - Introduction\n",
    "***\n",
    "\n",
    "* Decision trees are one of the most intuitive family of algorithms.\n",
    "* Extremely easy to understand\n",
    "* Checkout the decision tree below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Decision Trees - Representation\n",
    "***\n",
    "\n",
    "<center><img src=\"../images/tree2.png\" alt=\"Drawing\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision trees - Intuition\n",
    "***\n",
    "- Apart from being intuitive, we use decision trees because they can handle non-linearity in data\n",
    "\n",
    "- Since our observations tend to get jumbled up when we plot them, it's impossible to separate the data points linearly (this is what a simple Logistic Regression model would do) \n",
    "\n",
    "- In the image below, is the data Linearly Separable? \n",
    "\n",
    "<center><img src=\"../images/linearlyins.png\" alt=\"Drawing\" style=\"width: 400px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Answer: NO\n",
    "\n",
    "- This is where Decision Trees are very useful. \n",
    "- Through easy computational methods, Decision Trees are capable of complex methods of separation\n",
    "\n",
    "- But this also leads to ***overfitting***! We will see how to tackle that by tuning some parameters later on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision Trees - Types based on target variable\n",
    "***\n",
    "Types of decision tree are based on the type of target variable we have. It can be of two types:\n",
    "\n",
    "- **Categorical Variable Decision Tree**: Decision Tree which has categorical target variable then it called as categorical variable decision tree. Example:- In above scenario of student problem, where the target variable was “Student will play cricket or not” i.e. YES or NO.  (***CLASSIFICATION***)\n",
    "\n",
    "- **Continuous Variable Decision Tree**: Decision Tree has continuous target variable then it is called as Continuous Variable Decision Tree.  (***REGRESSION***)\n",
    "\n",
    "\n",
    "Before diving into the mathematics, let's get a better understanding of the Terminologies used in Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision Trees - Terminologies Used\n",
    "***\n",
    "Let's look at the basic terminology used with Decision trees:\n",
    "\n",
    "- **Root Node**: It represents entire population or sample and this further gets divided into two or more homogeneous sets.\n",
    "\n",
    "- **Splitting**: It is a process of dividing a node into two or more sub-nodes.\n",
    "\n",
    "- **Decision Node**: When a sub-node splits into further sub-nodes, then it is called decision node.\n",
    "\n",
    "- **Leaf/ Terminal Node**: Nodes that do not split are called Leaf or Terminal node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"../images/DT98.png\" alt=\"Drawing\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Decision Trees - Terminologies Used\n",
    "***\n",
    "***\n",
    "- **Pruning**: When we remove sub-nodes of a decision node, this process is called pruning. You can say opposite process of splitting\n",
    "- **Branch / Sub-Tree**: A sub section of entire tree is called branch or sub-tree.\n",
    "- **Parent and Child Node**: A node, which is divided into sub-nodes is called parent node of sub-nodes where as sub-nodes are the child of parent node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## SPLITS IN DECISION TREES\n",
    "***\n",
    "* It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. \n",
    "\n",
    "* A binary split is made on a feature.\n",
    "\n",
    "* The final result is a tree with decision nodes and leaf nodes.\n",
    "\n",
    "* The topmost decision node in a tree which corresponds to the best predictor called root node.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building our Intuition\n",
    "***\n",
    "- As usual, let's build our intuition on a problem based on a sort-of \"toy dataset\"\n",
    "\n",
    "- What is this dataset about?\n",
    "    - Let's say that the movie Dunkirk is running in the theaters\n",
    "    - Demographically, this movie has got a lot of mixed reviews\n",
    "\n",
    "\n",
    "- Let's have a look at the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>is_28+</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>watching</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>student</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>working</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>working</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>student</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>working</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender  is_28+ employment_status watching\n",
       "0      M       0           student      yes\n",
       "1      M       1           working      yes\n",
       "2      F       0           working      yes\n",
       "3      F       0           student       no\n",
       "4      M       1           working      yes"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "films = pd.read_csv('../data/films.csv')\n",
    "films.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## Decision Trees: How does it work?\n",
    "***\n",
    "\n",
    "We'll start with a very simple example: \n",
    "- We have a sample of 50 people with three variables Gender (M/F), employment status( Student/ Working) and Age (years)\n",
    "- Some of these 50 are planning to watch the movie.\n",
    "- Now, we want to create a model to predict who will watch the movie? In this problem, we need to segregate the sample into who will watch the movie based on highly significant input variable among all three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## Decision Trees: How does it work?\n",
    "***\n",
    "\n",
    "- A Decision Tree will segregate the movie watchers based on all values of three variable and identify the variable, which creates the sets so that all the members in the same groups are homogeneous to each other and heterogeneous to the other group.\n",
    "\n",
    "- Let's start with the target variable. As per the dataset, there are 26 people who want to watch the movie and 24 who don't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](../images/DT_master.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## Decision Trees: How does it work?\n",
    "***\n",
    "\n",
    "- Now, let's see how the three variables affect a person's movie watching decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](../images/DT_MF.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](../images/DT_age.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](../images/DT_emp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## Decision Trees: How does it work?\n",
    "***\n",
    "\n",
    "- As you can see from the images that `gender` splits the sample into most homogeneous groups\n",
    "- We can keep splitting our decision trees in the similar fashion, but as it turns out, mathematicians are smart! They have figured out a better way to split the decision trees. Let's see how."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## How does a tree decide where to split?\n",
    "***\n",
    "\n",
    "- Decision trees use multiple algorithms to decide to split a node in two or more sub-nodes.\n",
    "\n",
    "- The creation of sub-nodes increases the homogeneity of resultant sub-nodes\n",
    "\n",
    "- Decision tree **splits the nodes on all available variables** and then selects the split which results in most homogeneous sub-nodes\n",
    "\n",
    "** splits are done based on **\n",
    "1. Gini index\n",
    "2. Entropy\n",
    "3. Chi Squared\n",
    "***\n",
    "\n",
    "* We will understand the calculations behind these 3 concepts using our Film Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Technical-Stuff.png\" alt=\"Technical Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## Gini Index\n",
    "***\n",
    "\n",
    "Gini index says, if we select two items from a population at random then they must be of same class and probability for this is 1 if population is pure\n",
    "\n",
    "* It works with categorical target variable “Success” or “Failure”\n",
    "* A Gini score gives an idea of how good a split is by how mixed the classes are in the two groups created by the split.\n",
    "* It measures how often a randomly chosen element would be incorrectly identified.\n",
    "* A perfect separation results in a Gini score of 0, whereas the worst case split that results in 50/50 classes in each group results in a Gini score of 1.0 (for a 2 class problem).\n",
    "* Higher the value of Gini higher the homogeneity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to Calculate Gini Index?\n",
    "***\n",
    "1. Calculate Gini for sub-nodes, using formula sum of square of probability for success and failure \n",
    "$$(p^2+ (1-p)^2)$$.\n",
    "2. Calculate Gini for split using weighted Gini score of each node of that split\n",
    "\n",
    "Quickly, let's use the \"Students\" example to build our intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Before starting to split our Film Dataset based on a variable, let's see how many watched Dunkirk from our sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viewers who watched the movie:26\n",
      "Viewers who did not watch the movie:24\n"
     ]
    }
   ],
   "source": [
    "print(\"Viewers who watched the movie:{}\".format(len(films[films['watching'] == 'yes'])))\n",
    "print(\"Viewers who did not watch the movie:{}\".format(len(films[films['watching'] == 'no'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## SPLIT BASED ON GENDER :\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gender</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>watching</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "gender     F   M\n",
       "watching        \n",
       "no         8  16\n",
       "yes       14  12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crosstab1 = pd.crosstab(index=films[\"watching\"], columns=films[\"gender\"])\n",
    "crosstab1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Probabilities Calculation of male and female:**\n",
    "***\n",
    " $$ Females\\hspace{0.3cm}watched\\hspace{0.3cm}(yes) = \\frac{females\\hspace{0.3cm}who\\hspace{0.3cm}watched\\hspace{0.3cm}movies}{total\\hspace{0.3cm}females}$$\n",
    "\n",
    "$$ Males\\hspace{0.3cm}watched\\hspace{0.3cm}(yes) = \\frac{males\\hspace{0.3cm}who\\hspace{0.3cm}watched\\hspace{0.3cm}movies}{total\\hspace{0.3cm}males}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of males that watched Dunkirk:0.429\n",
      "Probability of females that watched Dunkirk:0.636\n"
     ]
    }
   ],
   "source": [
    "male_watched_yes = (12/float(28))\n",
    "female_watched_yes = (14/float(22))\n",
    "\n",
    "print(\"Probability of males that watched Dunkirk:{:.3f}\".format(male_watched_yes))\n",
    "print(\"Probability of females that watched Dunkirk:{:.3f}\".format(female_watched_yes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Gini Index Calculation for Males & Females**\n",
    "***\n",
    "$$gini(females)=(females\\hspace{0.3cm}watched\\hspace{0.3cm}yes)^2+(1-females\\hspace{0.3cm}watched\\hspace{0.3cm}yes)^2$$\n",
    "\n",
    "$$ gini(males)=(males\\hspace{0.3cm}watched\\hspace{0.3cm}yes)^2+(1-males\\hspace{0.3cm}watched\\hspace{0.3cm}yes)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini(female):0.537\n",
      "Gini(male):0.510\n"
     ]
    }
   ],
   "source": [
    "subnode_male = (male_watched_yes)**2 + (1-male_watched_yes)**2\n",
    "subnode_female = (female_watched_yes)**2 + (1-female_watched_yes)**2\n",
    "\n",
    "print(\"Gini(female):{:.3f}\".format(subnode_female))\n",
    "print(\"Gini(male):{:.3f}\".format(subnode_male))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Weighted Gini Index Calculation for Gender Split:**\n",
    "***\n",
    "$weighted\\hspace{0.3cm}gini(gender)=\\frac{males}{total}x(gini(males))+\\frac{females}{total}x(gini(females))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Gini for Gender:0.5221\n"
     ]
    }
   ],
   "source": [
    "calculated_wt_gender = (28/float(50))*subnode_male + (22/float(50))*subnode_female\n",
    "print(\"Weighted Gini for Gender:{:.4f}\".format(calculated_wt_gender))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## SPLIT BASED ON EMPLOYMENT\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>employment_status</th>\n",
       "      <th>student</th>\n",
       "      <th>working</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>watching</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "employment_status  student  working\n",
       "watching                           \n",
       "no                       5       19\n",
       "yes                      4       22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crosstab2 = pd.crosstab(index=films[\"watching\"], columns=films[\"employment_status\"])\n",
    "crosstab2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Probabilities Calculation :**\n",
    "$$(working\\hspace{0.3cm}watched\\hspace{0.3cm}yes)=\\frac{(working\\hspace{0.3cm}professionals\\hspace{0.3cm}who\\hspace{0.3cm}watched\\hspace{0.3cm}movie)}{(total\\hspace{0.3cm}working)}$$\n",
    "\n",
    "$$(student\\hspace{0.3cm}watched\\hspace{0.3cm}yes)=\\frac{(students\\hspace{0.3cm}\\hspace{0.3cm}who\\hspace{0.3cm}watched\\hspace{0.3cm}movie)}{(total\\hspace{0.3cm}students)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of students that watched:0.444\n",
      "Probability of working people that watched:0.537\n"
     ]
    }
   ],
   "source": [
    "student_watched_yes = (4/float(9))\n",
    "working_watched_yes = (22/float(41))\n",
    "print(\"Probability of students that watched:{:.3f}\".format(student_watched_yes))\n",
    "print(\"Probability of working people that watched:{:.3f}\".format(working_watched_yes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Gini Index Calculation :**\n",
    "![](../images/img2.png)\n",
    "$$gini(working)=(working\\hspace{0.3cm}watched\\hspace{0.3cm}yes)^2+(1-working\\hspace{0.3cm}watched\\hspace{0.3cm}yes)^2$$\n",
    "\n",
    "$$gini(students)=(students\\hspace{0.3cm}watched\\hspace{0.3cm}yes)^2+(1-students\\hspace{0.3cm}watched\\hspace{0.3cm}yes)^2$$\n",
    "* calculating Gini index for students who watched\n",
    "* calculating Gini index for employees who watched "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini(student):0.506\n",
      "Gini(working):0.503\n"
     ]
    }
   ],
   "source": [
    "subnode_student = (student_watched_yes)**2 + (1 - student_watched_yes)**2\n",
    "subnode_working = (working_watched_yes)**2 + (1 - working_watched_yes)**2\n",
    "\n",
    "print(\"Gini(student):{:.3f}\".format(subnode_student))\n",
    "print(\"Gini(working):{:.3f}\".format(subnode_working))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Weighted Gini Index for Employment Split :** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Gini(employment):0.5033\n"
     ]
    }
   ],
   "source": [
    "calculated_wt_emp = (41/float(50))*subnode_working + (9/float(50))*subnode_student\n",
    "print(\"Weighted Gini(employment):{:.4f}\".format(calculated_wt_emp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Since weighted gini(gender) > weighted gini(employment), the node split will take on Gender\n",
    "***\n",
    "- And now, you have developed a very strong basis on how splits take place based on the Gini Index/Score of Variables \n",
    "- Can you imagine how time consuming it would be if we had around 50+ variables? Not practical \n",
    "- Luckily, Sci-Kit Learn makes this easy for us \n",
    "\n",
    "- This also helps us judging the importance of variables. There's definitely a function to display the variables to and this could aid in Feature Selection as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## Chi-Square\n",
    "***\n",
    "\n",
    "It is an algorithm to find out the statistical significance between the differences between sub-nodes and parent node. We measure it by sum of squares of standardized differences between observed and expected frequencies of target variable.\n",
    "\n",
    "1. It works with categorical target variable “Success” or “Failure”\n",
    "2. It can perform two or more splits\n",
    "3. Higher the value of Chi-Square higher the statistical significance of differences between sub-node and Parent node.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## Chi-Square\n",
    "***\n",
    "\n",
    "4. Chi-Square of each node is calculated using formula,\n",
    "5. Chi-square = $((Actual – Expected)^2 / Expected)^{1/2}$\n",
    "6. It generates tree called CHAID (Chi-square Automatic Interaction Detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## Chi-Square\n",
    "***\n",
    "\n",
    "### Steps to Calculate Chi-Square: \n",
    "\n",
    "1. Calculate Chi-square for individual node by calculating the deviation for Success and Failure both\n",
    "2. Calculated Chi-square of Split using Sum of all Chi-square of success and Failure of each node of the split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Coming back to Dunkirk \n",
    "***\n",
    " - Let's now perform similar calculation in Python on our Dunkirk example.\n",
    " - By now you should get a good idea how this notebook is laid out. \n",
    "     - We're first building our intuition on an easy example (Students) \n",
    "     - Then we're directly calculating, in Python, the different scores for our Dunkirk Dataset\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dunkirk - Split on Gender\n",
    "***\n",
    "**Gender Node**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>watching</th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "watching  no  yes  Total\n",
       "gender                  \n",
       "F          8   14     22\n",
       "M         16   12     28"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crosstab1 = pd.crosstab(index=films[\"gender\"], columns=films[\"watching\"])\n",
    "crosstab1[\"Total\"] = crosstab1.no + crosstab1.yes\n",
    "crosstab1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Calculate the expected women who watch movie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>watching</th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "      <th>Total</th>\n",
       "      <th>Expected watch</th>\n",
       "      <th>Expected not watch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "watching  no  yes  Total  Expected watch  Expected not watch\n",
       "gender                                                      \n",
       "F          8   14     22            11.0                11.0\n",
       "M         16   12     28            14.0                14.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the expected women who watch movie\n",
    "\n",
    "crosstab1[\"Expected watch\"] = crosstab1.Total/2\n",
    "crosstab1[\"Expected not watch\"] = crosstab1.Total/2\n",
    "crosstab1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Calculating deviation\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>watching</th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "      <th>Total</th>\n",
       "      <th>Expected watch</th>\n",
       "      <th>Expected not watch</th>\n",
       "      <th>E - O (Watch)</th>\n",
       "      <th>E - O (Not Watch)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "watching  no  yes  Total  Expected watch  Expected not watch  E - O (Watch)  \\\n",
       "gender                                                                        \n",
       "F          8   14     22            11.0                11.0           -3.0   \n",
       "M         16   12     28            14.0                14.0            2.0   \n",
       "\n",
       "watching  E - O (Not Watch)  \n",
       "gender                       \n",
       "F                       3.0  \n",
       "M                      -2.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crosstab1[\"E - O (Watch)\"] = crosstab1[\"Expected watch\"] - crosstab1.yes\n",
    "crosstab1[\"E - O (Not Watch)\"] = crosstab1[\"Expected not watch\"] - crosstab1.no\n",
    "crosstab1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Formula to calculate chi-square : **\n",
    "***\n",
    "$$\\tilde{\\chi}^2=(\\frac{(actual-expected)^2}{expected})^{1/2}$$\n",
    "\n",
    "* calculating the chi square value for women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>watching</th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "      <th>Total</th>\n",
       "      <th>Expected watch</th>\n",
       "      <th>Expected not watch</th>\n",
       "      <th>E - O (Watch)</th>\n",
       "      <th>E - O (Not Watch)</th>\n",
       "      <th>chi2_watch</th>\n",
       "      <th>chi2_not_watch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.904534</td>\n",
       "      <td>0.904534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.534522</td>\n",
       "      <td>0.534522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "watching  no  yes  Total  Expected watch  Expected not watch  E - O (Watch)  \\\n",
       "gender                                                                        \n",
       "F          8   14     22            11.0                11.0           -3.0   \n",
       "M         16   12     28            14.0                14.0            2.0   \n",
       "\n",
       "watching  E - O (Not Watch)  chi2_watch  chi2_not_watch  \n",
       "gender                                                   \n",
       "F                       3.0    0.904534        0.904534  \n",
       "M                      -2.0    0.534522        0.534522  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crosstab1[\"chi2_watch\"] = np.sqrt(crosstab1[\"E - O (Watch)\"]**2/crosstab1[\"Expected watch\"])\n",
    "crosstab1[\"chi2_not_watch\"] = np.sqrt(crosstab1[\"E - O (Not Watch)\"]**2/crosstab1[\"Expected not watch\"])\n",
    "crosstab1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8781130351162796"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_gender = (crosstab1[\"chi2_watch\"] + crosstab1[\"chi2_not_watch\"]).sum()\n",
    "chi2_gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Split on Employment Status**\n",
    "***\n",
    "* We will perform Similar Calculations for splits on the *Employment Status* node\n",
    "* Get the total chi-squared value & compare it to our previous result to see which split is more effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>watching</th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "      <th>Total</th>\n",
       "      <th>Expected watch</th>\n",
       "      <th>Expected not watch</th>\n",
       "      <th>E - O (Watch)</th>\n",
       "      <th>E - O (Not Watch)</th>\n",
       "      <th>chi2_watch</th>\n",
       "      <th>chi2_not_watch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment_status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.235702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>working</th>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>41</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.5</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.331295</td>\n",
       "      <td>0.331295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "watching           no  yes  Total  Expected watch  Expected not watch  \\\n",
       "employment_status                                                       \n",
       "student             5    4      9             4.5                 4.5   \n",
       "working            19   22     41            20.5                20.5   \n",
       "\n",
       "watching           E - O (Watch)  E - O (Not Watch)  chi2_watch  \\\n",
       "employment_status                                                 \n",
       "student                      0.5               -0.5    0.235702   \n",
       "working                     -1.5                1.5    0.331295   \n",
       "\n",
       "watching           chi2_not_watch  \n",
       "employment_status                  \n",
       "student                  0.235702  \n",
       "working                  0.331295  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crosstab2 = pd.crosstab(index=films[\"employment_status\"], columns=films[\"watching\"])\n",
    "crosstab2[\"Total\"] = crosstab2.no + crosstab2.yes\n",
    "\n",
    "crosstab2[\"Expected watch\"] = crosstab2.Total/2\n",
    "crosstab2[\"Expected not watch\"] = crosstab2.Total/2\n",
    "\n",
    "crosstab2[\"E - O (Watch)\"] = crosstab2[\"Expected watch\"] - crosstab2.yes\n",
    "crosstab2[\"E - O (Not Watch)\"] = crosstab2[\"Expected not watch\"] - crosstab2.no\n",
    "\n",
    "crosstab2[\"chi2_watch\"] = np.sqrt(crosstab2[\"E - O (Watch)\"]**2/crosstab2[\"Expected watch\"])\n",
    "crosstab2[\"chi2_not_watch\"] = np.sqrt(crosstab2[\"E - O (Not Watch)\"]**2/crosstab2[\"Expected not watch\"])\n",
    "\n",
    "crosstab2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.133993677240111"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_emp = (crosstab2[\"chi2_watch\"] + crosstab2[\"chi2_not_watch\"]).sum()\n",
    "chi2_emp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Chi-squared values for GENDER is more than in employment status**\n",
    "***\n",
    "\n",
    "$\\tilde{\\chi}^2$ test also agrees with the Gini Index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## Entropy / Information Gain\n",
    "***\n",
    "\n",
    "From the image below, which of the three options can be described ***easily***?\n",
    "***\n",
    "<center><img src=\"../images/dt7.png\" alt=\"Drawing\" style=\"width: 650px;\"/></center>\n",
    "\n",
    "Image Source : https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## Entropy / Information Gain\n",
    "***\n",
    "\n",
    "- C because it requires less information as all the values are similar\n",
    "- On the other hand, B requires more information to describe it \n",
    "- A requires the maximum amount of information\n",
    "\n",
    "In other words, we can say that C is a Pure node, B is less Impure and A is more impure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## Entropy / Information Gain\n",
    "***\n",
    "\n",
    "- Now, we can conclude that less impure node requires less information to describe it\n",
    "\n",
    "- Concretely, a very impure node requires more information\n",
    "\n",
    "- **Information theory is a measure to define this degree of disorganization in a system known as Entropy.**\n",
    "\n",
    "- If the sample is completely homogeneous, then the entropy is zero and if the sample is an equally divided (50% – 50%), it has entropy of one. Let's understand how this is calculated and see what Information Gain really means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "## Entropy / Information Gain\n",
    "***\n",
    "Entropy can be calculated using formula:-\n",
    "\n",
    "$$ Entropy = -plog_{2}(p) - qlog_{2}(q) $$\n",
    "\n",
    "Here p and q are the probabilities of success and failure respectively in that node\n",
    "- Entropy is also used with categorical target variables. \n",
    "- It chooses the split which has lowest entropy compared to parent node and other splits\n",
    "- The lesser the entropy, the better it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## Entropy / Information Gain\n",
    "***\n",
    "\n",
    "$$Information Gain = Entropy of Parent node - [Weighted Avg]Entropy of Subnodes$$\n",
    "\n",
    "Steps to calculate entropy for a split:\n",
    "\n",
    "1. Calculate entropy of parent node\n",
    "2. Calculate entropy of each individual node of split and calculate weighted average of all sub-nodes available in split.\n",
    "\n",
    "** Now, let's build our intuition on the Students example, really quickly** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## Entropy / Information Gain\n",
    "***\n",
    "\n",
    "Above, you can see that entropy for Split on Gender is the lowest among all, so the tree will split on Gender\n",
    "\n",
    "Can you calculate the Information Gain for each split? It's pretty easy \n",
    "   - Remember: We are trying to **Maximize** Information Gain \n",
    "   - Which is **WHY**, mathematically, we choose the *minimum variable of Entropy* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Coming back to Dunkirk\n",
    "***\n",
    "Let's try and calculate the Entropy of the Parent node for the Dunkirk Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As usual, we're first going to try and split the node by Gender and then based on their Employment Status \n",
    "\n",
    "Let's calculate the entropy for the parent node: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988455359952018"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the parent entropy\n",
    "p = 26/float(50)\n",
    "q = 24/float(50)\n",
    "parent_entropy = -p*np.log2(p) - q*np.log2(q)\n",
    "parent_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Such a high entropy value suggest that this is almost an **impure** node.\n",
    "\n",
    "- Now, since we're splitting on the basis of Gender, let's calculate the Entropy for the Female and Male nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>watching</th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "watching  no  yes\n",
       "gender           \n",
       "F          8   14\n",
       "M         16   12"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crosstab1.iloc[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9456603046006401"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Female node entropy\n",
    "p = 14/float(22)\n",
    "q = 8/float(22)\n",
    "female_entropy = -p*np.log2(p) - q*np.log2(q)\n",
    "female_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9852281360342515"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Male node entropy\n",
    "p = 12/float(28)\n",
    "q = 16/float(28)\n",
    "male_entropy = -p*np.log2(p) - q*np.log2(q)\n",
    "male_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9678182902034626"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Weighted entropy for gender\n",
    "weighted_gender = (28/float(50))*male_entropy + (22/float(50))*female_entropy\n",
    "weighted_gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Can you calculate the Information Gain now? \n",
    " - You have the Entropy of the Parent Node \n",
    " - You have Weighted Average Entropy of the Female and Male nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## Calculate here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, let's do similar calculations if we were splitting our dataset on the basis of *Employment Status*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>watching</th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment_status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>working</th>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "watching           no  yes\n",
       "employment_status         \n",
       "student             5    4\n",
       "working            19   22"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crosstab2.iloc[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9910760598382222"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entropy for students\n",
    "p = 4/float(9)\n",
    "q = 5/float(9)\n",
    "student_entropy = -p*np.log2(p) - q*np.log2(q)\n",
    "student_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9961344835095796"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entropy for working people\n",
    "p = 22/float(41)\n",
    "q = 19/float(41)\n",
    "\n",
    "working_entropy = -p*np.log2(p) - q*np.log2(q)\n",
    "working_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9952239672487352"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_entropy = (41/float(50))*working_entropy + (9/float(50))*student_entropy\n",
    "weighted_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Since gender has least entropy, we will split the decision tree at gender. This is again in agreement with previous methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reduction in Variance\n",
    "***\n",
    "- Reduction in variance is an algorithm used for continuous target variables.\n",
    "- This algorithm uses standard formula of variance to choose the split. \n",
    "\n",
    "- The split with lower variance is selected as the criteria to split the problem :  \n",
    "***\n",
    "<center><img src=\"../images/dt10.png\" alt=\"Drawing\" style=\"width: 150px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Above X-bar is mean of the values, X is actual/observed value and n is number of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Steps to calculate Variance:\n",
    "***\n",
    "1) Calculate variance for each node\n",
    "\n",
    "2) Calculate variance for each split as weighted average of each node variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Above, you can see that the Gender split has lower variance compared to the parent node, so the split would take place on Gender variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Coming back to Dunkirk, again\n",
    "***\n",
    "\n",
    "* Let's assign 1 if someone is watching the film and 0 if he/she isn't watching the film \n",
    "* Based on this, let's perform the Variance Calculations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_root = (26*1 + 24*0)/float(50)\n",
    "mean_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24960000000000002"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_root = (26*(1-0.52)**2 + 24*(0-0.52)**2)/50\n",
    "var_root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Similarly, calculating variance for gender split we get: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>watching</th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "watching  no  yes  Total\n",
       "gender                  \n",
       "F          8   14     22\n",
       "M         16   12     28"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crosstab1.iloc[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_women = (14*1 + 8*0)/float(22)\n",
    "mean_women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23140509090909092"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variance for women\n",
    "var_women = (14*(1-0.636)**2 + 8*(0-0.636)**2)/22\n",
    "var_women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42857142857142855"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_men = (12*1 + 16*0)/float(28)\n",
    "mean_men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24489795918367346"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variance for men\n",
    "\n",
    "var_men = (12*(1 - mean_men)**2 + 16* (0 - mean_men)**2)/28\n",
    "var_men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23896109714285715"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted variance for gender split\n",
    "weighted_variance = (28/float(50)*var_men) + (22/float(50)*var_women)\n",
    "weighted_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Now let's do the needful if we're splitting our parent node based on *Employment Status*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "crosstab_var = crosstab2.iloc[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>watching</th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "      <th>Total</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment_status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>working</th>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>41</td>\n",
       "      <td>0.536585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "watching           no  yes  Total   average\n",
       "employment_status                          \n",
       "student             5    4      9  0.444444\n",
       "working            19   22     41  0.536585"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crosstab_var[\"average\"] = crosstab_var.yes*1/crosstab_var.Total\n",
    "crosstab_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>watching</th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "      <th>Total</th>\n",
       "      <th>average</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment_status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.246914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>working</th>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>41</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.248662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "watching           no  yes  Total   average  variance\n",
       "employment_status                                    \n",
       "student             5    4      9  0.444444  0.246914\n",
       "working            19   22     41  0.536585  0.248662"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variance\n",
    "\n",
    "crosstab_var[\"variance\"] = (crosstab_var.yes * (1 - crosstab_var.average)**2 \n",
    "                            + crosstab_var.no * (0 - crosstab_var.average)**2) / crosstab_var.Total\n",
    "\n",
    "crosstab_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24834688346883468"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_emp = (41/float(50))*crosstab_var.loc[\"working\", \"variance\"]\\\n",
    "                    + (9/float(50))*crosstab_var.loc[\"student\", \"variance\"]\n",
    "weighted_emp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Here, variance (weighted_emp) split is slightly higher than variance (weighted_gender) split.**\n",
    "***\n",
    "- Above, you can see that Gender split has lowest variance compare to parent node, so the split would take place on Gender variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Python Implementation\n",
    "***\n",
    "\n",
    "- We have learned, to quite some detail, how the algorithm decides to split the parent node\n",
    "- Let's see how to implement a decision tree model in Python! \n",
    "\n",
    "- Let's import the necessary libraries, etc. We already know how to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Importing necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Reading data & seperating it into train and test\n",
    "# Splitting the data into training and target set\n",
    "\n",
    "dataframe = pd.read_csv('../data/loan_prediction.csv')\n",
    "X = dataframe.iloc[:,0:5]\n",
    "y = dataframe.iloc[:,5]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Decision Tree using the Gini Index criterion**\n",
    "***\n",
    "- Here, let's check the accuracy of the Gini Index method on our training set. \n",
    "- Do you remember how Accuracy is calculated? \n",
    "    - If not, now is a good time to pause and ponder. It has something to do with the Confusion Matrix.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.654054054054054"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gini = DecisionTreeClassifier(criterion='gini')\n",
    "clf_gini.fit(X_train,y_train)\n",
    "\n",
    "y_prediction_gini = clf_gini.predict(X_test)\n",
    "accuracy_gini = accuracy_score(y_test,y_prediction_gini)\n",
    "\n",
    "accuracy_gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Decision Tree using the Information Gain / Entropy criterion**\n",
    "***\n",
    "- Similar calculations here too.\n",
    "\n",
    "- We saw that for the Gini Index method we got an accuracy of ~64.5% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6216216216216216"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_entropy = DecisionTreeClassifier(criterion='entropy')\n",
    "clf_entropy.fit(X_train,y_train)\n",
    "y_prediction_entropy = clf_entropy.predict(X_test)\n",
    "accuracy_entropy = accuracy_score(y_test,y_prediction_entropy)\n",
    "accuracy_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Plotting a decision tree\n",
    "\n",
    "Decision tree can be plotted using `pydotplus`. Here is an example. For this you will have to install pydotplus.<br/>\n",
    "Do a `pip install pydotplus` <br/>\n",
    "And also do a `sudo apt-get install graphviz` in your terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Let's alter some parameters of this Decision Tree in order to prevent over-fitting and get a better accuracy. (we got accuracies below ~ 70% which suggest that our models were not that good) \n",
    "\n",
    "So, what are the key parameters of tree modeling and how can we avoid over-fitting in decision trees?\n",
    "\n",
    " - Let's discuss this and build our intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Shortcomings decision trees\n",
    "\n",
    "- Overfitting is one of the key challenges faced while modeling decision trees\n",
    "- If there is no limit set of a decision tree, it will give you 100% accuracy on training set because in the worse case it will end up making 1 leaf for each observation\n",
    "- Thus, preventing overfitting is pivotal while modeling a decision tree and it can be done in 2 ways:\n",
    "\n",
    "    - Setting constraints on tree size\n",
    "    - Tree pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## Setting Constraints \n",
    "***\n",
    "\n",
    "- First, lets look at the general structure of a decision tree:\n",
    "\n",
    "<center><img src=\"../images/dt12.png\" alt=\"Drawing\" style=\"width: 750px;\"/></center>\n",
    "<br/>\n",
    "Image Source : https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Minimum samples for a node split**\n",
    " - Defines the minimum number of samples (or observations) which are required in a node to be considered for splitting.\n",
    " - Used to control over-fitting. Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree.\n",
    " - Too high values can lead to under-fitting hence, it should be tuned using CV.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Minimum samples for a terminal node (leaf)**\n",
    " - Defines the minimum samples (or observations) required in a terminal node or leaf.\n",
    " - Used to control over-fitting similar to min_samples_split.\n",
    " - Generally lower values should be chosen for imbalanced class problems because the regions in which the minority class will be in majority will be very small.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Maximum depth of tree (vertical depth)**\n",
    "\n",
    "- Used to control over-fitting as higher depth will allow model to learn relations very specific to a particular sample.\n",
    "- Should be tuned using CV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Maximum number of terminal nodes**\n",
    " - The maximum number of terminal nodes or leaves in a tree.\n",
    " - Can be defined in place of max_depth. Since binary trees are created, a depth of ‘n’ would produce a maximum of $2^n$ leaves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Maximum features to consider for split**\n",
    " - The number of features to consider while searching for a best split. These will be randomly selected.\n",
    " - As a thumb-rule, square root of the total number of features works great but we should check upto 30-40% of the total number of features.\n",
    " - Higher values can lead to over-fitting but depends on case to case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Approach -2 : Effect of varying max_depth\n",
    "***\n",
    "\n",
    "Let's choose **Depths of 2 and 5 respectively **and then compared the results to see which is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_1 = DecisionTreeClassifier(max_depth = 2)\n",
    "clf_1.fit(X_train,y_train)\n",
    "\n",
    "clf_2 = DecisionTreeClassifier(max_depth = 5)\n",
    "clf_2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# predicting for both max depth 2 and 5.\n",
    "\n",
    "y_clf_1 = clf_1.predict(X_test)\n",
    "y_clf_2 = clf_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#calculate accuracy\n",
    "accuracy_clf_1 = accuracy_score(y_test,y_clf_1)\n",
    "accuracy_clf_2 = accuracy_score(y_test,y_clf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7297297297297297"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_clf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6810810810810811"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_clf_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Better Results: \n",
    "***\n",
    "- By comparing these results with what we got before \n",
    "- We can notice that the accuracies of both these models is better than the models before ( ~ 64%) \n",
    "\n",
    "**NOTE** : In Python, the default criterion to make the splits is the Gini Index unless specified otherwise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Advantages of Decision Trees: \n",
    "***\n",
    "1) Easy to Understand: \n",
    "- Decision tree output is very easy to understand even for people from non-analytical background. \n",
    "- It does not require any statistical knowledge to read and interpret them.\n",
    "- Its graphical representation is very intuitive and users can easily relate their hypothesis.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2) Useful in Data exploration: \n",
    "- Decision tree is one of the fastest way to identify most significant variables and relation between two or more variables. - With the help of decision trees, we can create new variables / features that has better power to predict target variable. -  It can also be used in data exploration stage. For example, we are working on a problem where we have information available in hundreds of variables, there decision tree will help to identify most significant variable.\n",
    "\n",
    "3) Less data cleaning required: \n",
    "- It requires less data cleaning compared to some other modeling techniques.\n",
    "- It is not influenced by outliers and missing values to a fair degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "4) Data type is not a constraint:\n",
    "- It can handle both numerical and categorical variables.\n",
    "\n",
    "5) Non Parametric Method: \n",
    "- Decision tree is considered to be a non-parametric method. \n",
    "- This means that decision trees have no assumptions about the space distribution and the classifier structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Drawbacks of Decision Trees\n",
    "***\n",
    "* Decision-tree learners can create over-complex trees that do not generalise the data well. This is called overfitting.\n",
    "\n",
    "* Decision trees can be unstable because small variations in the data might result in a completely different tree being generated.\n",
    "\n",
    "* Decision tree learners create biased trees if some classes dominate. It is therefore recommended to balance the dataset prior to fitting with the decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Recap.png\" alt=\"Recap\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "# In-session Recap Time\n",
    "***\n",
    "\n",
    "- What is Decision Trees and how to use it?\n",
    "- Splits in Decision Trees\n",
    "    - Gini Index\n",
    "    - Entropy\n",
    "    - Chi Squared\n",
    "- Advantages of Decision Trees\n",
    "- Drawbacks of Decsion Trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wbc = pd.read_csv('../data/wbc.csv')\n",
    "df_wbc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 1\n",
    "***\n",
    "\n",
    "Drop the column `Unnamed: 32` from diabetes dataset and split the predictors and target variables into variables X and y for training and testing and then use `train_test_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 2\n",
    "***\n",
    "\n",
    "On the wbc dataset loaded and split into train and test above, fit a decision tree classifier model with `max_depth=4`, `min_samples_leaf=0.16`, `random_state=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 3\n",
    "***\n",
    "\n",
    "Check the accuracy score for the model and classification report for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 4\n",
    "***\n",
    "\n",
    "Create a dictionary having possible parameter as `max_depth` with length equal to total number of samples. Create the GridSearchCV object. Fit the data with the best possible parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 5\n",
    "***\n",
    "\n",
    "Print the best estimator with it's parameters. And also the best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank You\n",
    "***\n",
    "### Coming up next...\n",
    "***\n",
    "- Ensembling & Random Forest\n",
    "\n",
    "For more queries - Reach out to www.vikas-ai.com"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
